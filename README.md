# AlexNet_Plant_Disease_Detection

The plants pruning to diseases have a significant negative impact on food production. If the diseases don’t been recognized early, food insecurity will occur. Early detection is the basis for effective prevention and control of plant diseases, and they play a vital role in the management and decision-making of agricultural production. In recent years, plant disease identification has been a crucial issue.

AlexNet consists of 8 layers, including 5 convolutional layers and 3 fully connected layers. It uses large convolutional kernels, ReLU activation functions and Dropout regularization. 

Plant diseases can cause significant economic losses for farmers, agricultural industries, and the overall economy. Agriculture plays a crucial role in ensuring food security. Plant diseases can cause crop losses, affecting food production and supply, which in turn can impact food prices and availability. Traditional methods rely on visual inspection by human experts, which can be time consuming and prone to human-error. Some plant diseases can spread rapidly, and early detection is crucial to prevent further contamination and control over the spread of disease. Efficient disease detection allows for targeted and precise application of pesticides and treatments, reducing the overall usage of chemicals and promoting sustainable agricultural practices. Deep learning algorithms, such as CNNs, can automate the disease detection process, reducing the need for manual labor and time-consuming visual inspections. Automated systems can efficiently process a large number of plant images, making it easier to monitor and manage extensive agricultural areas.

To train the model with uniform images, image augmentation techniques are applied to increase the diversity of the training dataset. It is not so sure that every image is taken from same background and at a same distance hence, Techniques like rotation, scaling, and flipping introduce variations that help the model generalize better to different conditions. Resizing every image and normalizing them are performed. Images are resized to a consistent input size, ensuring uniformity in data dimensions across the network. Normalization, which involves scaling pixel values, aids in reducing the impact of lighting and color variations. Every image has pixel values in the range of 0 to 256 therefore, every image’s pixel value is brought within the range of 0 to 1. There are several ways to train the model like transfer learning, using RNNs, one shot earning etc. this paper aims to initialize the model for every architecture from the scratch. This includes Data preparation i.e.; we preprocessed a diverse dataset of leaf images including both healthy and diseased samples. We then resized every image into corresponding model’s input shape (e.g., 224x224x3) and normalize pixel values to a common range (0 to 1). To prevent overfitting, data augmentation techniques such as rotating every image, zooming, shearing, shifting height and width, flipping are performed. Then we chose a pretrained CNN architecture and added layers, used kernels, activation functions, regularization techniques such as dropout and batch normalization according to the model requirements. We then specified the optimizer (e.g., Adam) to update model weights during training. Next, we chose a suitable loss function (e.g., categorical cross-entropy) to measure the difference between predicted and actual class probabilities. After compiling the model, we fed the preprocessed and augmented training data into the model and train it over multiple epochs, defined evaluation metrics (e.g., accuracy) to monitor training progress. We monitored training and validation loss and accuracy to detect overfitting or underfitting. We utilized techniques like early stopping to prevent overfitting, set verbose to 1 to get to know about training time and metrics for each epoch. We used model checkpoints to save only the best weights. We then visualized learning of model with the data and plotted training and validation loss and accuracy. We then fed the test images through the model and obtain predicted probabilities for each disease class. We then converted predicted probabilities to class predictions selecting the highest probability. Next is the metrics calculation, we calculated various metrics such as accuracy, precision, recall, and F1-score to evaluate the model's performance. Confusion matrix is derived to understand how well the model is classifying each disease. Both the training and testing phases involve iterative processes, with adjustments made to architecture, hyperparameters, and data as needed. 
